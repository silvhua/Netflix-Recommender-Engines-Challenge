{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1Riw_TiDgX3szaba1KR4FfM2SLA5Ni-4d",
      "authorship_tag": "ABX9TyNMP2QNnRv7b6D0zfA9oZLp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silvhua/Netflix-Recommender-Engines-Challenge/blob/main/recommender_engines_II_2022_12_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab stuff"
      ],
      "metadata": {
        "id": "FCJXFpCfuPv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can see what GPU you've been assigned at any time by executing the following cell\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "# You can see how much memory you have available at any time by running the following code cell. \n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "555znCt1RgMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d4fa15a-bec4-49b8-b46c-512f4693e75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 14 01:18:01 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    27W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "FBAPp5DGuUKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8HIFkZwcRgHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies = pd.read_csv('/content/drive/MyDrive/data exercises/W10/netflix-challenge/movie_titles.csv', header=None, \n",
        "    encoding = \"ISO-8859-1\", # As per https://www.kaggle.com/code/laowingkin/netflix-movie-recommendation\n",
        "    usecols=[0, 1, 2], # Required because some movie titles (column 2) have commas, causing parser error otherwise\n",
        "    names=['Movie_Id', 'Year', 'Name'])\n",
        "movies.head()"
      ],
      "metadata": {
        "id": "DwmfMclVRgBk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "39275a38-45b8-4219-cdf2-cfd3a9739e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Movie_Id    Year                          Name\n",
              "0         1  2003.0               Dinosaur Planet\n",
              "1         2  2004.0    Isle of Man TT 2004 Review\n",
              "2         3  1997.0                     Character\n",
              "3         4  1994.0  Paula Abdul's Get Up & Dance\n",
              "4         5  2004.0      The Rise and Fall of ECW"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67549b13-73aa-45f5-a4ec-bd680fb705fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Movie_Id</th>\n",
              "      <th>Year</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>Dinosaur Planet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>Isle of Man TT 2004 Review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>Character</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1994.0</td>\n",
              "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2004.0</td>\n",
              "      <td>The Rise and Fall of ECW</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67549b13-73aa-45f5-a4ec-bd680fb705fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67549b13-73aa-45f5-a4ec-bd680fb705fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67549b13-73aa-45f5-a4ec-bd680fb705fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all ratings data\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/data exercises/W10/netflix-challenge/combined_data_1.txt', header=None, names=['Customer', 'Rating', 'Date'], usecols = [0,1,2])\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/data exercises/W10/netflix-challenge/combined_data_2.txt', header=None, names=['Customer', 'Rating', 'Date'], usecols = [0,1,2])\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/data exercises/W10/netflix-challenge/combined_data_3.txt', header=None, names=['Customer', 'Rating', 'Date'], usecols = [0,1,2])\n",
        "df4 = pd.read_csv('/content/drive/MyDrive/data exercises/W10/netflix-challenge/combined_data_4.txt', header=None, names=['Customer', 'Rating', 'Date'], usecols = [0,1,2])"
      ],
      "metadata": {
        "id": "54sWHPxtRf-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used this as an example: https://www.kaggle.com/code/morrisb/how-to-recommend-anything-deep-recommender\n",
        "from collections import deque \n",
        "def reshape_df(df):\n",
        "    tmp_movies = df[df['Rating'].isna()]['Customer'].reset_index()\n",
        "    movie_index = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
        "\n",
        "    # Shift the movie_indices by one to get start and endpoints of all movies\n",
        "    shifted_movie_index = deque(movie_index)\n",
        "    shifted_movie_index.rotate(-1)\n",
        "    user_data = []\n",
        "    for [df_id1, movie_id1], [df_id2, movie_id2] in zip(movie_index, shifted_movie_index):\n",
        "        # check if last movie in the file\n",
        "        if df_id1 < df_id2:\n",
        "            tmp_df = df.loc[df_id1+1: df_id2-1].copy()\n",
        "        else:\n",
        "            tmp_df = df.loc[df_id1+1:].copy()\n",
        "        # create movie_id column\n",
        "        tmp_df['Movie_ID'] = movie_id1\n",
        "        user_data.append(tmp_df)\n",
        "    df2 = pd.concat(user_data)\n",
        "    del user_data, df, tmp_df\n",
        "    print('Shape:', df2.shape)\n",
        "    return df2\n"
      ],
      "metadata": {
        "id": "wPdja5wwy_Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a single dataframe with all the ratings\n",
        "df = pd.concat([df1, df2, df3, df4]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "_RkSfptA0peM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape the dataframe\n",
        "df0 = reshape_df(df)\n",
        "df0.to_csv('/content/drive/MyDrive/data exercises/W10/netflix-challenge/combined_data_reshaped.csv')\n",
        "del df1, df2, df3, df4"
      ],
      "metadata": {
        "id": "Cw0NyYKGzAde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load processed CSV"
      ],
      "metadata": {
        "id": "_ZjUOTWmNvP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_csv(filename,filepath,column1_as_index=False,truncate=None, usecols=None, sep=','):\n",
        "    \"\"\"\n",
        "    Load a csv file as a dataframe using specified file path copied from windows file explorer.\n",
        "    Back slashes in file path will be converted to forward slashes.\n",
        "    Arguments:\n",
        "    - filepath (raw string): Use the format r'<path>'.\n",
        "    - filename (string).\n",
        "    - colum1_as_index (bool): If true, take the first column as the index. \n",
        "        Useful when importing CSV files from previously exported dataframes.\n",
        "\n",
        "    Returns: dataframe object.\n",
        "    \"\"\"\n",
        "    filename = f'{filepath}/'.replace('\\\\','/')+filename\n",
        "    df = pd.read_csv(filename, usecols=usecols, sep=sep)\n",
        "    if column1_as_index==True:\n",
        "        df.set_index(df.columns[0], inplace=True)\n",
        "        df.index.name = None\n",
        "    print('Dataframe shape: ',df.shape)\n",
        "\n",
        "    if truncate:\n",
        "        return df.sample(n=truncate,random_state=0)\n",
        "    else:\n",
        "        return df\n",
        "\n",
        "df0 = load_csv('/content/drive/MyDrive/data exercises/W10/netflix-challenge/combined_data_reshaped.csv',filepath='',\n",
        "               column1_as_index=True)\n",
        "df0.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "5N6makooNuzd",
        "outputId": "6bb13192-22d1-412c-9c73-3177404f3f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe shape:  (100480507, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Customer  Rating        Date  Movie_ID\n",
              "1   1488844     3.0  2005-09-06         1\n",
              "2    822109     5.0  2005-05-13         1\n",
              "3    885013     4.0  2005-10-19         1\n",
              "4     30878     4.0  2005-12-26         1\n",
              "5    823519     3.0  2004-05-03         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b503813-99f0-4ec9-b3ca-427fb58f4c44\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Customer</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Date</th>\n",
              "      <th>Movie_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1488844</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2005-09-06</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>822109</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2005-05-13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>885013</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2005-10-19</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30878</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2005-12-26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>823519</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2004-05-03</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b503813-99f0-4ec9-b3ca-427fb58f4c44')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b503813-99f0-4ec9-b3ca-427fb58f4c44 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b503813-99f0-4ec9-b3ca-427fb58f4c44');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plan\n",
        "1. Predict Ratings\n",
        "  *   Surprise algorithms with and without hyperparameter tuning\n",
        "    * SVD\n",
        "    * SVDpp\n",
        "    * NMF\n",
        "  * Linear regression\n",
        "  * SVD plus bias with different `n_component` values\n",
        "\n",
        "2. Make recommendations using the best estimator"
      ],
      "metadata": {
        "id": "LiWraZEBwq9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scikit Surprise"
      ],
      "metadata": {
        "id": "PZh4eIdswWwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-u57wAuwMr3",
        "outputId": "4c4489b1-d3b7-4e57-b30d-f16756f848d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[K     |████████████████████████████████| 771 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise) (1.7.3)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp38-cp38-linux_x86_64.whl size=2626468 sha256=39917d7dc7432b2961d923ff6a13b69987979ace435dcec062d899b68a80fc80\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/db/86/2c18183a80ba05da35bf0fb7417aac5cddbd93bcb1b92fd3ea\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # import dataset from surprise\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "\n",
        "# Create data set in surprise format\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "# Loads Pandas dataframe\n",
        "data = Dataset.load_from_df(df0[['Customer', 'Movie_ID', 'Rating']], reader)"
      ],
      "metadata": {
        "id": "BBemmjrtRf7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.model_selection import train_test_split\n",
        "# Train test split\n",
        "trainset, testset = train_test_split(data, test_size=.15)\n",
        "del data"
      ],
      "metadata": {
        "id": "FP1G-dtsRf1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trainset and test set\n",
        "import pickle\n",
        "with open('/content/drive/MyDrive/data exercises/W10/netflix-challenge/surprise_trainset.pickle', 'wb') as fh:\n",
        "  pickle.dump(trainset, fh)\n",
        "with open('/content/drive/MyDrive/data exercises/W10/netflix-challenge/surprise_testset.pickle', 'wb') as fh2:\n",
        "  pickle.dump(testset, fh2)"
      ],
      "metadata": {
        "id": "isadaxdPUeT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `surprise_predictions` function and SVD algorithm"
      ],
      "metadata": {
        "id": "IXcEpFqwdQPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import SVD from surprise\n",
        "from surprise import SVD\n",
        "\n",
        "# import accuracy from surprise\n",
        "from surprise import accuracy\n",
        "\n",
        "# import GridSearchCV from surprise.model_selection\n",
        "from surprise.model_selection import GridSearchCV\n",
        "# import cross_validate from surprise.model_selection\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "\n",
        "def surprise_gridsearch_predictions(estimator, param_grid, data, pickle_name=None):\n",
        "  \"\"\"\n",
        "  Perform gridsearch with surprise data set.\n",
        "  \"\"\"\n",
        "  gs = GridSearchCV(estimator, param_grid, measures={'rmse'})\n",
        "  gs.fit(data)\n",
        "  print('Best grid search parameters:', gs.best_params['rmse'])\n",
        "  predictions = gs.test(testset)\n",
        "  rmse = accuracy.rmse(predictions)\n",
        "  print(f'Model RMSE: {rmse:.2f}')\n",
        "  filepath = '/content/drive/MyDrive/data exercises/W10/netflix-challenge/saved_models/'\n",
        "  if pickle:\n",
        "    with open(filepath+pickle_name+'_model.pickle', 'wb') as fh:\n",
        "      pickle.dump(gs.best_estimator_, fh)\n",
        "    with open(filepath+pickle_name+'_predictions.pickle', 'wb') as fh2:\n",
        "      pickle.dump(predictions, fh)\n",
        "  return gs.best_estimator_, predictions\n",
        "\n",
        "  \n",
        "def surprise_predictions(algorithm, trainset=trainset, testset=testset, pickle_name=None):\n",
        "  output = algorithm.fit(trainset)\n",
        "  predictions = algorithm.test(testset)\n",
        "  rmse = accuracy.rmse(predictions)\n",
        "  print(f'Model RMSE: {rmse:.2f}')\n",
        "  if pickle_name:\n",
        "    try:\n",
        "      filepath = '/content/drive/MyDrive/data exercises/W10/netflix-challenge/saved_models/'\n",
        "      with open(filepath+pickle_name+'_model.pickle', 'wb') as fh:\n",
        "        pickle.dump(algorithm, fh)\n",
        "      with open(filepath+pickle_name+'_predictions.pickle', 'wb') as fh2:\n",
        "        pickle.dump(predictions, fh)\n",
        "      print(f'Saved: {filepath+pickle_name}_model.pickle')\n",
        "      print(f'Saved: {filepath+pickle_name}_predictions.pickle')\n",
        "    except:\n",
        "      print('Outputs not saved')\n",
        "    return algorithm, predictions\n",
        "\n",
        "\n",
        "model_svd, predictions_svd = surprise_predictions(SVD(), pickle_name='surpriseSVD')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gftPPouPsDB",
        "outputId": "078d0862-57d5-49be-f11d-dd2d099b3e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.8333\n",
            "Model RMSE: 0.83\n",
            "Outputs not saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filepath = '/content/drive/MyDrive/data exercises/W10/netflix-challenge/saved_models/'\n",
        "pickle_name='surpriseSVD'\n",
        "with open(filepath+pickle_name+'_model.pickle', 'wb') as fh:\n",
        "  pickle.dump(model_svd, fh)\n"
      ],
      "metadata": {
        "id": "Bv_NL2IU705z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(filepath+pickle_name+'_predictions.pickle', 'wb') as fh2:\n",
        "  pickle.dump(predictions_svd, fh2)\n",
        "print(f'Saved: {filepath+pickle_name}_predictions.pickle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTkaTac2lLiQ",
        "outputId": "b01fc70a-3975-424f-ccbc-1bbd0239f6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/data exercises/W10/netflix-challenge/saved_models/surpriseSVD_predictions.pickle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_factors': [75, 100, 125],\n",
        "    'lr_all': [0.005, 0.01],\n",
        "}\n"
      ],
      "metadata": {
        "id": "PeYMWm7tRfyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVDpp algorithm"
      ],
      "metadata": {
        "id": "qlyHAkcldbqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from surprise import SVDpp\n",
        "model_svdpp, predictions_svdpp = surprise_predictions(SVDpp(), pickle_name='surpriseSVDpp')\n",
        "# Not sure why, but after 8 h 37 min using Google Colab Pro+ with Premium GPU, got an error saying that cell execution failed"
      ],
      "metadata": {
        "id": "Kw0yVNc_Rfp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NMF"
      ],
      "metadata": {
        "id": "ikwi8lN4EHSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc6QUTalIJ_Y",
        "outputId": "e7d4520e-aab9-4046-8a7a-1ed47b938756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[K     |████████████████████████████████| 771 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise->surprise) (1.7.3)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp38-cp38-linux_x86_64.whl size=2626486 sha256=ff4a9e4ddf15b2e32f3ceb791df029afc26c80e7986bb9d6876151d1e071b98a\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/db/86/2c18183a80ba05da35bf0fb7417aac5cddbd93bcb1b92fd3ea\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.3 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "def savepickle(model,filename, ext='sav', path='/content/drive/MyDrive/data exercises/W10/netflix-challenge/',append_version=False):\n",
        "    \"\"\"\n",
        "    Export object as a pickle.\n",
        "    Parameters:\n",
        "    - model: Model variable name.\n",
        "    - filename: Root of the filename.\n",
        "    - extension: Extension to append (do not include dot as it will be added)\n",
        "    - filepath (raw string): Use the format r'<path>'. If None, file is saved in same director.\n",
        "    - append_version (bool): If true, append date and time to end of filename.\n",
        "    \"\"\"\n",
        "    if path:\n",
        "        path = f'{path}/'.replace('\\\\','/')\n",
        "    if append_version == True:\n",
        "        filename+=datetime.now().strftime('%Y-%m-%d_%H%M')\n",
        "    with open (path+filename+'.'+ext, 'wb') as fh:\n",
        "        pickle.dump(model, fh)\n",
        "    print('File saved: ',path+filename+'.'+ext)\n",
        "\n",
        "def loadpickle(filename,filepath='/content/drive/MyDrive/data exercises/W10/netflix-challenge/'):\n",
        "    \"\"\"\n",
        "    Load a pickled model using specified file path copied from windows file explorer.\n",
        "    Back slashes in file path will be converted to forward slashes.\n",
        "    Arguments:\n",
        "    - filepath (raw string): Use the format r'<path>'.\n",
        "    - filename (string).\n",
        "    \n",
        "    Returns saved object.\n",
        "    \"\"\"\n",
        "    filename = filepath+filename\n",
        "    loaded_model = pickle.load(open(filename, 'rb'))\n",
        "    return loaded_model\n",
        "\n",
        "trainset = loadpickle('surprise_trainset.pickle')\n",
        "testset = loadpickle('surprise_testset.pickle')"
      ],
      "metadata": {
        "id": "RWVQZGfHFXo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import accuracy\n",
        "def surprise_predictions(algorithm, trainset=trainset, testset=testset, pickle_name=None):\n",
        "  output = algorithm.fit(trainset)\n",
        "  predictions = algorithm.test(testset)\n",
        "  rmse = accuracy.rmse(predictions)\n",
        "  print(f'Model RMSE: {rmse:.2f}')\n",
        "  if pickle_name:\n",
        "    try:\n",
        "      filepath = '/content/drive/MyDrive/data exercises/W10/netflix-challenge/saved_models/'\n",
        "      with open(filepath+pickle_name+'_model.pickle', 'wb') as fh:\n",
        "        pickle.dump(algorithm, fh)\n",
        "      print(f'Saved: {filepath+pickle_name}_model.pickle')\n",
        "      with open(filepath+pickle_name+'_predictions.pickle', 'wb') as fh2:\n",
        "        pickle.dump(predictions, fh2)\n",
        "      print(f'Saved: {filepath+pickle_name}_predictions.pickle')\n",
        "    except:\n",
        "      print('Outputs not saved')\n",
        "    return algorithm, predictions"
      ],
      "metadata": {
        "id": "Qe8roxhRQPqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import NMF\n",
        "model_NMF, predictions_NMF = surprise_predictions(NMF(), pickle_name='surpriseNMF')"
      ],
      "metadata": {
        "id": "DlAjFM63Rfcz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5afad0d0-55fa-4796-f7b0-9bca708f4830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9256\n",
            "Model RMSE: 0.93\n",
            "Saved: /content/drive/MyDrive/data exercises/W10/netflix-challenge/saved_models/surpriseNMF_model.pickle\n",
            "Outputs not saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filepath = '/content/drive/MyDrive/data exercises/W10/netflix-challenge/saved_models/'\n",
        "pickle_name='surpriseNMF'\n",
        "with open(filepath+pickle_name+'_predictions.pickle', 'wb') as fh2:\n",
        "      pickle.dump(predictions_NMF, fh2)\n",
        "print(f'Saved: {filepath+pickle_name}_predictions.pickle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "h_VUcPrvf5Re",
        "outputId": "a16910ea-2dac-4a00-b663-094fedc0566d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f722a606509c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpickle_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'surpriseNMF'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpickle_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_predictions.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_NMF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Saved: {filepath+pickle_name}_predictions.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predictions_NMF' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Randomized SVD\n",
        "Predict rating based on [Sci-kit Surprise's SVD algorithm](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#matrix-factorization-based-algorithms): \n",
        "rui = mu + bu + bi + qi'*pu"
      ],
      "metadata": {
        "id": "_i3uDjPsITia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_csv(filename,filepath,column1_as_index=False,truncate=None, usecols=None, sep=','):\n",
        "    \"\"\"\n",
        "    Load a csv file as a dataframe using specified file path copied from windows file explorer.\n",
        "    Back slashes in file path will be converted to forward slashes.\n",
        "    Arguments:\n",
        "    - filepath (raw string): Use the format r'<path>'.\n",
        "    - filename (string).\n",
        "    - colum1_as_index (bool): If true, take the first column as the index. \n",
        "        Useful when importing CSV files from previously exported dataframes.\n",
        "\n",
        "    Returns: dataframe object.\n",
        "    \"\"\"\n",
        "    filename = f'{filepath}/'.replace('\\\\','/')+filename\n",
        "    df = pd.read_csv(filename, usecols=usecols, sep=sep)\n",
        "    if column1_as_index==True:\n",
        "        df.set_index(df.columns[0], inplace=True)\n",
        "        df.index.name = None\n",
        "    print('Dataframe shape: ',df.shape)\n",
        "\n",
        "    if truncate:\n",
        "        return df.sample(n=truncate,random_state=0)\n",
        "    else:\n",
        "        return df\n",
        "        \n",
        "def create_matrix(df, index='Customer', columns='Movie_ID', values='Rating', pickle_name=None):\n",
        "  \"\"\"\n",
        "  Create a utility matrix. This can then be used for randomizedSVD by converting into csr_matrix\n",
        "  and filling nan with zero.\n",
        "  \"\"\"\n",
        "  df = df.pivot_table(index=index, columns=columns, values=values)\n",
        "  \n",
        "  if pickle_name:\n",
        "    try:\n",
        "      filepath = '/content/drive/MyDrive/data exercises/W10/netflix-challenge/saved_models/'\n",
        "      with open(filepath+pickle_name+'_sparse_utility_matrix.pickle') as fh:\n",
        "        pickle.dump(df, fh)\n",
        "      print(f'Saved: {filepath+pickle_name}_sparse_utility_matrix.pickle')\n",
        "    except:\n",
        "      print('Unable to save outputs')\n",
        "  return df\n",
        "\n",
        "df0 = load_csv('/content/drive/MyDrive/data exercises/W10/netflix-challenge/combined_data_reshaped.csv',filepath='',\n",
        "               column1_as_index=True)\n",
        "utility_matrix = create_matrix(df0)"
      ],
      "metadata": {
        "id": "Z6d9beS_RfLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36fc6a0c-a7cc-4bf6-deee-7f64806349fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe shape:  (100480507, 4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-73044e0a831b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m df0 = load_csv('/content/drive/MyDrive/data exercises/W10/netflix-challenge/combined_data_reshaped.csv',filepath='',\n\u001b[1;32m     46\u001b[0m                column1_as_index=True)\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mutility_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-73044e0a831b>\u001b[0m in \u001b[0;36mcreate_matrix\u001b[0;34m(df, index, columns, values, pickle_name)\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mand\u001b[0m \u001b[0mfilling\u001b[0m \u001b[0mnan\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \"\"\"\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpickle_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot_table\u001b[0;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m   7949\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7951\u001b[0;31m         return pivot_table(\n\u001b[0m\u001b[1;32m   7952\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7953\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pivot_table\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     table = __internal_pivot_table(\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36m__internal_pivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mto_unstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_unstack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdropna\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(self, level, fill_value)\u001b[0m\n\u001b[1;32m   8322\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8324\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unstack\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36munstack\u001b[0;34m(obj, level, fill_value)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_unstack_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m_unstack_frame\u001b[0;34m(obj, level, fill_value)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0munstacker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Unstacker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         return unstacker.get_result(\n\u001b[1;32m    476\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, index, level, constructor)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_rows\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnum_columns\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnum_cells\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unstacked DataFrame is too big, causing int32 overflow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_selectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unstacked DataFrame is too big, causing int32 overflow"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.extmath import randomized_svd\n",
        "from scipy.sparse import csr_matrix\n",
        "def run_svd(utility_matrix, n_components_list, pickle_name=None):\n",
        "  print('Original array shape: ', matrix.shape)\n",
        "  U_dict = dict()\n",
        "  S_dict = dict()\n",
        "  VT_dict = dict()\n",
        "  predictions_dict = dict()\n",
        "  for n_components in n_components_list:\n",
        "    U_dict[n_components], S_dict[n_components], VT_dict[n_components] = randomized_svd(\n",
        "        csr_matrix(utility_matrix.fillna(0)), n_components=n_components, random_state=0)\n",
        "    # Reconstruct the decomposed matrix\n",
        "    reconst = U_dict[n_components].dot(np.diag(S_dict[n_components])).dot(VT_dict[n_components])\n",
        "    print(f'n_components:', n_components)\n",
        "    print('Reconstructed array shape:', reconst.shape)\n",
        "    print('\\tU shape: ',U_dict[n_components].shape)\n",
        "    print('\\tSigma shape: ', S_dict[n_components].shape)\n",
        "    print('\\tV shape: ',VT_dict[n_components].shape)\n",
        "    try:\n",
        "      # Mean rating in array (nan values excluded)\n",
        "      mu = utility_matrix.values.reshape(-1)[~np.isnan(utility_matrix.values.reshape(-1))].mean()\n",
        "\n",
        "      # Array with bias per user. Reshape to be array with same number of rows as customers.\n",
        "      bu = (utility_matrix.mean(axis=1) - utility_matrix.mean(axis=1).mean()).to_numpy().reshape(-1,1)\n",
        "\n",
        "      # Array with bias per item. Reshape to be array with same number of columns as movies.\n",
        "      bi = (utility_matrix.mean() - utility_matrix.mean().mean()).to_numpy().reshape(1,-1)\n",
        "\n",
        "      predicted_ratings = (mu + bu + bi + reconst) - utility_matrix.fillna(0).values\n",
        "      print('Predictions matrix shape:', predictions_dict[n_components].shape)\n",
        "      predictions_dict[n_components] = pd.DataFrame(\n",
        "          predicted_ratings, index=utility_matrix.index, columns=utility_matrix.columns)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  if pickle_name:\n",
        "    try:\n",
        "      filepath = '/content/drive/MyDrive/data exercises/W10/netflix-challenge/saved_models/'\n",
        "      with open(filepath+pickle_name+'_randomizedSVD_U_dict.pickle', 'wb') as fh:\n",
        "        pickle.dump(U_dict, fh)\n",
        "      print(f'Saved: {filepath+pickle_name}_randomizedSVD_U_dict.pickle')\n",
        "      with open(filepath+pickle_name+'_randomizedSVD_S_dict.pickle', 'wb') as fh2:\n",
        "        pickle.dump(S_dict, fh2)\n",
        "      print(f'Saved: {filepath+pickle_name}_randomizedSVD_S_dict.pickle')\n",
        "      with open(filepath+pickle_name+'_randomizedSVD_VT_dict.pickle', 'wb') as fh3:\n",
        "        pickle.dump(VT_dict, fh3)\n",
        "      print(f'Saved: {filepath+pickle_name}_randomizedSVD_VT_dict.pickle')\n",
        "      with open(filepath+pickle_name+'_randomizedSVD_predictions_dict.pickle', 'wb') as fh4:\n",
        "        pickle.dump(predictions_dict, fh4)\n",
        "      print(f'Saved: {filepath+pickle_name}_randomizedSVD_VT_dict.pickle')\n",
        "    except:\n",
        "      print('Outputs not saved')\n",
        "\n",
        "  return U_dict, S_dict, VT_dict, predictions_dict\n",
        "\n",
        "n_components_list = [20, 50]\n",
        "U_dict, S_dict, VT_dict, predictions_dict = run_svd(matrix, n_components_list, pickle_name='netflix')"
      ],
      "metadata": {
        "id": "Oz23pTMJRfVK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}